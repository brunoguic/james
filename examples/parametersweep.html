---
layout: default
---

<div>
    <ol class="breadcrumb">
        <li><a href="/index.html">Home</a></li>
        <li><a href="/examples">Examples</a></li>
        <li class="active">Parameter sweep</li>
    </ol>
    
    <h2 class="page-header">
        Example 5A: Parameter sweep
    </h2>
    
    <div class="bs-callout bs-callout-info">
        <h4>
            <i class="fa fa-info-circle"></i>
            Info
        </h4>
        Several Metropolis searches are applied to find an
        appropriate temperature range for parallel tempering. Don't know what Metropolis search is?
        Read <a href="/docs/#metropolis-search">this</a>. Never heard about parallel tempering?
        Read <a href="/docs/#parallel-tempering">this</a>.
    </div>
    <p>
        This example demonstrates how to find an appropriate temperature range for parallel tempering using the
        automated analysis workflow from the <a href="/getstarted/#modules">extensions module</a>. The core subset selection
        problem from <a href="/examples/coresubset3/">example 1C</a> is used as a case study. Several Metropolis
        searches with different fixed temperatures are applied. The results are then inspected using the provided
        <a href="/getstarted/#r-package">R package</a>, to infer the temperature range to be used in a
        parallel tempering algorithm.
    </p>
    
    <h4 class="page-header">
        Run Metropolis searches with different temperatures
    </h4>
    <p>
        To find an appropriate temperature range for a parallel tempering algorithm, we will run several Metropolis
        searches with different temperatures and assess their performance for a series of datasets. Each dataset
        consists of a distance matrix based on which the entry-to-nearest-entry score of the selected subset is
        computed (see <a href="/examples/coresubset3/">example 1C</a>). This score is to be maximized.
        To execute the algorithms and gather statistics about the obtained solution quality, convergence, etc.
        we will use the analysis workflow included in the <a href="/getstarted/#modules">extensions module</a>.
        This requires to add this module as a dependency to your project, in addition to the core module.
    </p>
    <p>
        The first step is to create an analysis object.
    </p>
<pre class="prettyprint">
// initialize analysis object
Analysis&lt;SubsetSolution&gt; analysis = new Analysis&lt;&gt;();
</pre>
    <p>
        Then, the problems to be analyzed are added. In this example there is one problem for each
        considered dataset and they all have the same entry-to-nearest-entry objective. Data is read
        from CSV files using the <code>CoreSubsetFileReader</code> which is included in the full
        <a href="https://github.com/hdbeukel/james-examples/tree/v{{site.examples-latest-stable}}/src/main/java/org/jamesframework/examples/coresubset">source code</a>
        of <a href="/examples/coresubset/">example 1A</a> where the corresponding data type
        <code>CoreSubsetData</code> is also defined. The <code>EntryToNearestEntryObjective</code>
        is taken from <a href="/examples/coresubset3/">example 1C</a>.
    </p>
    <p>
        The size of the constructed core is determined relative to the size of the full dataset by specifying a fixed
        selection ratio (e.g. 0.2).
        Every problem that is added to the analysis needs to be assigned a unique (string) ID.
        Here, the CSV file name is used as the ID (without directories and without extension).
    </p>
<pre class="prettyprint">
// set input file paths
List&lt;String&gt; filePaths = Arrays.asList("my/input/file1.csv", "my/input/file2.csv", ...);
// read datasets
CoreSubsetFileReader reader = new CoreSubsetFileReader();
List&lt;CoreSubsetData&gt; datasets = new ArrayList&lt;&gt;();
for(String filePath : filePaths){
  datasets.add(reader.read(filePath));
}

// create objective
EntryToNearestEntryObjective obj = new EntryToNearestEntryObjective();

// set selection ratio
double selRatio = 0.2;
// add problems (one per dataset)
for(int d=0; d &lt; datasets.size(); d++){
    // create problem
    CoreSubsetData data = datasets.get(d);
    int coreSize = (int) Math.round(selRatio * data.getIDs().size());
    SubsetProblem&lt;CoreSubsetData&gt; problem = new SubsetProblem&lt;&gt;(obj, data, coreSize);
    // set problem ID to file name (without directories and without extension)
    String path = filePaths.get(d);
    String filename = new File(path).getName();
    String id = filename.substring(0, filename.lastIndexOf("."));
    // add problem to analysis
    analysis.addProblem(id, problem);
}
</pre>
    <p>
        ...
    </p>
<pre class="prettyprint">
// create stop criterion
long timeLimit = 300;
StopCriterion stopCrit = new MaxRuntime(timeLimit, TimeUnit.SECONDS);

// set temperature range
double minTemp = 1e-8;
double maxTemp = 1e-3;
// set number of Metropolis searches
int numSearches = 10;
// create and add searches
double tempDelta = (maxTemp - minTemp)/(numSearches - 1);
for(int s=0; s &lt; numSearches; s++){
    // set temperature
    double temp = minTemp + s * tempDelta;
    // add Metropolis search
    String id = "MS-" + (s+1);
    analysis.addSearch(id, problem -> {
        Search&lt;SubsetSolution&gt; ms = new MetropolisSearch&lt;&gt;(problem, new SingleSwapNeighbourhood(), temp);
        ms.addStopCriterion(stopCrit);
        return ms;
    });
}
</pre>
<pre class="prettyprint">
...
// set number of runs
analysis.setNumRuns(runs);
</pre>
    
    <h4 class="page-header">
        Full source code
    </h4>
    <p>
        The complete source code of this example is available on
        <a href="https://github.com/hdbeukel/james-examples/tree/v{{site.examples-latest-stable}}/src/main/java/org/jamesframework/examples/analysis">GitHub</a>.
        You can also download a <a href="/getstarted/#releases-examples">ZIP file</a> that contains the Java sources of all examples, a compiled
        JAR (including all dependencies) as well as some input files for in case you want to run any of the examples. To run this example, execute
    </p>
<pre class="prettyprint">
$ java -cp james-examples.jar org.jamesframework.examples.analysis.ParameterSweep &lt;selectionratio&gt; &lt;runs&gt; &lt;runtime&gt; &lt;mintemp&gt; &lt;maxtemp&gt; &lt;numsearches&gt; [ &lt;inputfile&gt; ]+
</pre>
    </p>
        from the command line.
        The selection ratio determines the core size. The following arguments specify the number of runs (repeats)
        that will be performed for each search, the runtime limit (in seconds) of each run, the minimum and maximum temperature
        and the actual number of Metropolis searches (i.e. number of considered temperatures).
        The input files (at least one) should be CSV files in which the first row contains N
        item names and the subsequent N rows specify an N &times; N distance matrix.
        The analysis will be repeated for each dataset loaded from the given files.
        All output is combined into a single file <code>ParameterSweep.json</code> that
        can be loaded in R using the provided <a href="/getstarted/#r-package">R package</a>.
    </p>
    <p>
        <a href="/files/examples/coresubset.zip"><i class="fa fa-file-archive-o"></i> Input files (ZIP)</a>
    </p>
    
</div>


















