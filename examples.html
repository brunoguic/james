---
layout: default
---

<div id="examples">
    <ol class="breadcrumb">
        <li><a href="/index.html">Home</a></li>
        <li class="active">Examples</li>
    </ol>

    <div class="row">
    
        <!-- content -->
        <div class="col-lg-9">

            <h1 id="page-header" class="page-header">
                Examples
            </h1>
            <p>
                Step-by-step implementation guides are provided here for a series of examples. The full source code
                of all examples is bundled in the James examples module. You can browse the code on
                <a href="https://github.com/hdbeukel/james/tree/v{{site.examples-latest-stable}}/james/james-examples">GitHub</a>
                or download a <a href="/getstarted/#releases-examples">ZIP file</a> that contains all
                Java sources, a compiled JAR (including all dependencies) as well as example input files in
                case you want to run any of the examples.
            </p>
            
            <h2 id="subset-selection" class="page-header">
                Subset selection problems
            </h2>
            <p>
                These examples show how to specify a subset selection problem
                and how to apply a variety of searches to find good solutions.
            </p>
            
            <h4 id="subset-selection" class="page-header example-header">
                Example 1: Core subset selection
                <span class="hidden-xs">
                    <span class="pull-right label label-warning">
                        Difficulty:
                        <i class="fa fa-star-half-full"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                    </span>
                </span>
            </h4>
            <p class="lead">
                Basic fixed size subset selection. Optimization algorithm: random descent with a predefined
                subset neighbourhood (single swap).
            </p>
            <p>
                The core subset selection problem originates from the field of crop science. Given a large collection
                of crop varieties, the goal is to select a maintainable subset that represents
                the diversity of the entire collection as much as possible. There are several approaches
                to this problem, with distinct objective functions.
            </p>
            <p>
                This example discusses the implementation of a simplified core subset selection problem in James.
                It is assumed that a distance matrix is available in which the dissimilarity of any pair of crop
                varieties is expressed. The goal is to select a subset of fixed size with maximum average distance
                between all pairs of selected items.
            </p>
            <p>
                The basic <a href="/docs/#random-descent">random descent</a> algorithm is applied to sample a core subset,
                using a predefined subset neighbourhood that swaps a single selected and unselected ID to modify the
                current solution.
            </p>
            <p>
                <a class="btn btn-default" href="/examples/coresubset"><i class="fa fa-chevron-right"></i> View example</a>
            </p>
            
            <h4 class="page-header example-header">
                Example 2: The 0/1 knapsack problem
                <span class="hidden-xs">
                    <span class="pull-right label label-warning">
                        Difficulty:
                        <i class="fa fa-star"></i>
                        <i class="fa fa-star-half-full"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                    </span>
                </span>
            </h4>
            <p class="lead">
                Variable size subset selection with constraints. Optimization algorithms: random descent and parallel tempering
                with a predefined subset neighbourhood (single perturbation).
            </p>
            <p>
                The 0/1 knapsack problem is a contrained variable size subset selection problem. The input consists of a list of items
                which each have a fixed weight and profit. The goal is to select a subset of these items with maximal total profit where
                the total weight does not exceed a given knapsack capacity.
            </p>
            <p>
                The <a href="/docs/#random-descent">random descent</a> and <a href="/docs/#parallel-tempering">parallel tempering</a>
                algorithms are applied to optimize the selected subset, using a predefined subset neighbourhood that adds, deletes or
                swaps a (pair of) ID(s) to modify the current selection.
            </p>
            <p>
                <a class="btn btn-default" href="/examples/knapsack"><i class="fa fa-chevron-right"></i> View example</a>
            </p>
            
            <h4 class="page-header example-header">
                Example 3: The maximum clique problem
                <span class="hidden-xs">
                    <span class="pull-right label label-warning">
                        Difficulty:
                        <i class="fa fa-star"></i>
                        <i class="fa fa-star"></i>
                        <i class="fa fa-star-half-full"></i>
                        <i class="fa fa-star-o"></i>
                        <i class="fa fa-star-o"></i>
                    </span>
                </span>
            </h4>
            <p class="lead">
                Variable size subset selection with a custom greedy neighbourhood. Optimization algorithms: random descent
                and variable neighbourhood search.
            </p>
            <p>
                The maximum clique problem originates from graph theory and has many applications in e.g. social networks, bioinformatics
                and computational chemistry. The goal is to find a clique of maximum size in a given graph. Such clique consists of a subset
                of vertices which are all connected to each other (a complete subgraph).
            </p>
            <p>
                The <a href="/docs/#random-descent">random descent</a> and <a href="/docs/#vns">variable neighbourhood search</a>
                algorithms are applied to search for a maximum clique. The algorithms start from an empty clique and use a custom greedy
                neighbourhood that always adds a single vertex which is connected to all vertices in the current clique. The variable
                neighbourhood search also uses custom shaking neighbourhoods to escape from local optima.
            </p>
            <p>
                <a class="btn btn-default" href="/examples/clique"><i class="fa fa-chevron-right"></i> View example</a>
            </p>
            
            <h2 id="beyond-subset-selection" class="page-header">
                Beyond subset selection
            </h2>
            <p>
                These examples show how to implement and solve other types of problems.
            </p>
            
            <div class="bs-callout bs-callout-info">
                <h4>
                    <i class="fa fa-info-circle"></i>
                    Info
                </h4>
                Examples coming soon.
            </div>
            
        </div><!-- end of content -->      
    
</div>
